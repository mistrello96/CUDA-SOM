Anche con 30000 reads, ho 1200 neuroni, quindi non ha senso spostare la computazione su gpu per cercare il minimo BMU, overhead troppo elevato, servirebbero 30000 neuroni per attutire l'overhead, quindi 36000000 reads. La differenza di prestazioni cala mano a mano che le reads crescono, su 30000 reads sono 3 volte + lento

Ha senso usare thrust sulla media della accuracy(numerosit√† come le reads), non ha senso sulla BMU distance.

La simulazione ci mette 3,7 per ogni epoch su normal data.

TODO:

-Questione Toroidale

-Stima blocchi e threads

-Aggiungere kernel update per non effettuare memcopy(Nessuno da host accede alla matrice.


STRINGA DI COMPILAZIONE:

nvcc -std=c++11 -Xptxas -O3 --use_fast_math -gencode arch=compute_20,code=compute_20 -gencode arch=compute_30,code=compute_30 -gencode arch=compute_35,code=compute_35 -gencode arch=compute_50,code=compute_50 ./src/SOM.cu ./src/cmdline.c 




TEMPI

	std::chrono::high_resolution_clock::time_point start = std::chrono::high_resolution_clock::now();
	std::chrono::high_resolution_clock::time_point end = std::chrono::high_resolution_clock::now();
	std::cout << "!!!!!! " << (double)std::chrono::duration_cast<std::chrono::microseconds>( end - start ).count() / 1000000 << " seconds" <<std::endl;



            if(radius == 0){
                update_BMU<<<1, 1>>>(d_Matrix, d_Samples, lr, currentIndex, nElements, BMU_index);
            }
            else{
                update_SOM<<<nblocks, 32>>>(d_Matrix, d_Samples, lr, currentIndex, nElements, BMU_index, nColumns, radius, nNeurons);
            }
