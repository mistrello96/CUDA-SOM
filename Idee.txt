Anche con 30000 reads, ho 1200 neuroni, quindi non ha senso spostare la computazione su gpu per cercare il minimo BMU, overhead troppo elevato, servirebbero 30000 neuroni per attutire l'overhead, quindi 36000000 reads. La differenza di prestazioni cala mano a mano che le reads crescono, su 30000 reads sono 3 volte + lento

Ha senso usare thrust sulla media della accuracy(numerosit√† come le reads), non ha senso sulla BMU distance.


TODO:

-Questione Toroidale

-Stima blocchi e threads


STRINGA DI COMPILAZIONE:

nvcc -std=c++11 -Xptxas -O3 --use_fast_math -gencode arch=compute_20,code=compute_20 -gencode arch=compute_30,code=compute_30 -gencode arch=compute_35,code=compute_35 -gencode arch=compute_50,code=compute_50 ./src/SOM.cu ./src/cmdline.c 

RISULTATI SBAGLIATI
Learning rate of this iteration is 0.1
Radius of this iteration is 25
Mean distance of this iteration is 0.000901124
Learning rate of this iteration is 0.0802
Radius of this iteration is 20
Mean distance of this iteration is 0.000753676
Learning rate of this iteration is 0.0604
Radius of this iteration is 15
Mean distance of this iteration is 0.000554812
Learning rate of this iteration is 0.0406
Radius of this iteration is 10
Mean distance of this iteration is 0.000286698
Learning rate of this iteration is 0.0208
Radius of this iteration is 5
Mean distance of this iteration is 6.78593e-05
